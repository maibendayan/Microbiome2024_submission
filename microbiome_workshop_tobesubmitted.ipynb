{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import braycurtis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose your working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=f\"{os.getcwd()}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWkJCPlpoIhV"
   },
   "source": [
    "### Read train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "hSuoc3yToGS5"
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "metadata_path = rf\"{base_path}train_metadata.csv\"\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "data_path = rf\"{base_path}train_data.csv\"\n",
    "data_df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading DFs for the final prediction\n",
    "* We were given test data that contained both samaples with microbiome data and samples without it. Therefore, we merged the train data we were given at milestone 1 with the test samples that came with microbiome data (x_train and y_train).\n",
    "* The actual test data is the test metadata that did not contain microbiome data (x_test). Predicted microbiome data will be submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata_path = f\"{base_path}test_metadata.csv\"\n",
    "test_metadata_df = pd.read_csv(test_metadata_path)\n",
    "test_metadata_df.set_index('sample',inplace=True)\n",
    "\n",
    "test_data_path = f\"{base_path}short_timeseries_data.csv\"\n",
    "test_data_df = pd.read_csv(test_data_path)\n",
    "test_data_df.set_index('sample',inplace=True)\n",
    "\n",
    "# X_test\n",
    "indexes_with_no_data = test_metadata_df.index.difference(test_data_df.index)\n",
    "actual_test_metadata_df=test_metadata_df.loc[indexes_with_no_data,:]\n",
    "\n",
    "# X_train\n",
    "updated_train_metadata_df=pd.concat([metadata_df.set_index('sample'),test_metadata_df.loc[test_data_df.index,:]])\n",
    "updated_train_metadata_df.reset_index(inplace=True)\n",
    "\n",
    "# y_train\n",
    "updated_train_data_df=pd.concat([data_df.set_index('sample'),test_data_df])\n",
    "updated_train_data_df.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUJqPMWaPbqV"
   },
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "0iFPoG_7t4y5"
   },
   "outputs": [],
   "source": [
    "def preprocess(metadata_df, data_df, data_exists=True):\n",
    "\n",
    "  if data_exists:\n",
    "    data_columns=list(data_df.columns)\n",
    "    metadata_columns=list(metadata_df.columns)\n",
    "\n",
    "    # sample will be set as index\n",
    "    data_columns.remove(\"sample\")\n",
    "    metadata_columns.remove(\"sample\")\n",
    "\n",
    "    # merge to keep all rows aligned in metadata and data \n",
    "    merged_df=data_df.merge(metadata_df,on='sample', how='inner')\n",
    "    merged_df = merged_df.set_index('sample')\n",
    "\n",
    "    # sort by date\n",
    "    merged_df = merged_df.sort_values(by='collection_date')\n",
    "    \n",
    "    # split after sort, copy so the original will not be changed\n",
    "    sorted_metadata_df=merged_df[metadata_columns].copy()\n",
    "    sorted_data_df=merged_df[data_columns].copy()\n",
    "  else:\n",
    "    sorted_metadata_df=metadata_df.copy().sort_values(by='collection_date')\n",
    "    sorted_data_df=None\n",
    "\n",
    "  samples_for_index = sorted_metadata_df.index\n",
    "\n",
    "  # create time features\n",
    "  sorted_metadata_df[['year', 'month', 'day']] = sorted_metadata_df['collection_date'].str.split('-', expand=True).apply(pd.to_numeric) # split columns manually\n",
    "  sorted_metadata_df['collection_date'] = pd.to_datetime(sorted_metadata_df['collection_date'])\n",
    "  sorted_metadata_df['date_diff'] = sorted_metadata_df['collection_date'].diff().dt.days\n",
    "  # fill NA: first value will be 0\n",
    "  sorted_metadata_df['date_diff'] = sorted_metadata_df['date_diff'].fillna(0) \n",
    "\n",
    "  sorted_metadata_df.drop(columns=['collection_date'], inplace=True)\n",
    "\n",
    "  # catagorial to numerical\n",
    "  potenital_categorial = ['baboon_id', 'sex', 'social_group', 'season']\n",
    "  categorical_columns = [col for col in potenital_categorial if col in sorted_metadata_df.columns] # try run with and without social group!\n",
    "  encoder = OneHotEncoder(sparse_output=False)\n",
    "  X_categorical = encoder.fit_transform(sorted_metadata_df[categorical_columns])\n",
    "  X_categorical_df = pd.DataFrame(X_categorical, columns=encoder.get_feature_names_out(categorical_columns), index=samples_for_index)\n",
    "  X_numerical_df = sorted_metadata_df[[col for col in sorted_metadata_df.columns if col not in categorical_columns]]\n",
    "\n",
    "  sorted_metadata_df = pd.concat([X_categorical_df, X_numerical_df], axis=1)\n",
    "\n",
    "  print(f'number of features after onehot: {sorted_metadata_df.shape[1]}')\n",
    "  print(sorted_metadata_df.columns.tolist())\n",
    "\n",
    "  return sorted_metadata_df , sorted_data_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data\n",
    "* Naive splitting the dataset into train and test, 20% test, 80% train. samples are sorted by data, so most recent samples are chosen to be test.\n",
    "    * Was eventually not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "_-Tb1LcpyiVB"
   },
   "outputs": [],
   "source": [
    "def preprocess_after_filter(metadata_df, data_df):\n",
    "\n",
    "  X=metadata_df.values\n",
    "  y = data_df[data_df.columns].values\n",
    "  split_index = int(0.8 * len(metadata_df))\n",
    "  X_train, X_test = X[:split_index], X[split_index:]\n",
    "  y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "  return X_train, X_test, y_train, y_test, data_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Splitting the data by baboon ID, so the train will contain 80% of the baboons and the test will contain 20%. Allows us to evaluate our model on new set of Baboons that the model was not trained on.\n",
    "    * Random split means the train dataset size vary, but we see it stays constant around +-4900.\n",
    "    * Chosen for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_per_monkey(metadata_df, data_df):\n",
    "    \n",
    "    # Get the unique IDs\n",
    "    baboon_id_columns = [col for col in metadata_df.columns if col.startswith('baboon_id_Baboon_')]\n",
    "    unique_baboon_ids = [col.split('_')[-1] for col in baboon_id_columns]\n",
    "    \n",
    "    # Split the baboon IDs into train and test sets (80% train, 20% test)\n",
    "    train_baboons, test_baboons = train_test_split(unique_baboon_ids, test_size=0.2)\n",
    "    \n",
    "    print(\"number of train baboons\", len(train_baboons))\n",
    "    print(\"number of test baboons\", len(test_baboons))\n",
    "    \n",
    "    # Create masks to filter metadata_df and data_df for training and testing based on baboon IDs\n",
    "    train_mask = metadata_df[baboon_id_columns].apply(lambda row: any(row[col] == 1 for col in baboon_id_columns if col.split('_')[-1] in train_baboons), axis=1)\n",
    "    test_mask = metadata_df[baboon_id_columns].apply(lambda row: any(row[col] == 1 for col in baboon_id_columns if col.split('_')[-1] in test_baboons), axis=1)\n",
    "    \n",
    "    x_train = metadata_df[train_mask]\n",
    "    x_test = metadata_df[test_mask]\n",
    "    y_train = data_df[train_mask]\n",
    "    y_test = data_df[test_mask]\n",
    "\n",
    "    print(f'number of samples in train dataset: {len(x_train)}')\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvcFViDrB-3I"
   },
   "source": [
    "### Add Features\n",
    "* Add previous samples to the train metadata:\n",
    "    * n_prevs: number of added samples\n",
    "    * Use all microbe columns if microb == \"\", otherwise use the specified microbe column\n",
    "    * deprecated but stays for future directions: runs PCA on those columns only if microb=\"\" (does not predict each microbe seperetaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "WKVSY3gcD5h5"
   },
   "outputs": [],
   "source": [
    "def add_prev(metadata_df, data_df, n_prevs, microb=\"\"):\n",
    "\n",
    "    combined_df = metadata_df.join(data_df)\n",
    "\n",
    "    # Use all microbe columns if microb == \"\", otherwise use the specified microbe column\n",
    "    if microb == \"\":\n",
    "        microbe_columns = [col for col in data_df.columns if col.startswith('g_')]\n",
    "    else:\n",
    "        if isinstance(microb, list): # recieved more then one -> list\n",
    "            microbe_columns=microb\n",
    "        else:\n",
    "            microbe_columns = [microb] # recieved one -> string\n",
    "\n",
    "    if n_prevs == 0:\n",
    "        return metadata_df\n",
    "\n",
    "    for prev in range(1, n_prevs + 1):\n",
    "        print(\"doing prev number\", prev)\n",
    "        # New column names for previous microbe data, init with NA\n",
    "        previous_microbe_columns = [f'prev{prev}_{col}' for col in microbe_columns]\n",
    "        combined_df[previous_microbe_columns] = None\n",
    "\n",
    "        for baboon_id in [col for col in combined_df.columns if 'baboon_id' in col]:\n",
    "            # get the df indexes in which the baboon appears\n",
    "            baboon_indices = combined_df[combined_df[baboon_id] == 1].index.tolist()\n",
    "\n",
    "            # init average value for early samples (no prev)\n",
    "            avg_val=combined_df[combined_df[baboon_id] == 1][microbe_columns].mean(axis=0)\n",
    "            current_index = [baboon_indices[i] for i in range(0,min(prev,len(baboon_indices)))]\n",
    "            combined_df.loc[current_index, previous_microbe_columns] = avg_val.values\n",
    "            \n",
    "            # ADD PREV!\n",
    "            for i in range(prev, len(baboon_indices)):\n",
    "                current_index = baboon_indices[i]\n",
    "                previous_index = baboon_indices[i - prev]\n",
    "                combined_df.loc[current_index, previous_microbe_columns] = combined_df.loc[previous_index, microbe_columns].values\n",
    "\n",
    "        # Fill NaN values with 0\n",
    "        combined_df[previous_microbe_columns] = combined_df[previous_microbe_columns].fillna(0)\n",
    "\n",
    "        # If using all microbiome (microb == \"\"), apply scaling and PCA\n",
    "        if microb == \"\" and False:\n",
    "            pca = PCA(n_components=2)\n",
    "            normalized_data = normalize(combined_df[previous_microbe_columns], norm='l1', axis=1)\n",
    "            pca_result = pca.fit_transform(normalized_data)\n",
    "\n",
    "\n",
    "            # Create PCA column names for the reduced components\n",
    "            pca_columns = [f'prev{prev}_PC1', f'prev{prev}_PC2']\n",
    "            combined_df[pca_columns] = pca_result\n",
    "\n",
    "            # Only keep the PCA columns in the final output\n",
    "            result_df = combined_df[pca_columns]\n",
    "        else:\n",
    "            # keep the original previous microbe columns\n",
    "            result_df = combined_df[previous_microbe_columns]\n",
    "\n",
    "        # Merge the result back into metadata\n",
    "        metadata_df = metadata_df.join(result_df)\n",
    "\n",
    "\n",
    "    return metadata_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoSIaf3p4MbD"
   },
   "source": [
    "### Create prediction\n",
    "1. Process test metadata: add initial PREV generated by the train data distribution. Subsequential samples' PREV will be added iteritivly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# microbiome_lst - all microbiome. next func takes only the required data\n",
    "def process_test_metadata(test_metadata_df, train_data_df, n_prevs):\n",
    "    # no prev -> no need to add anything. return.\n",
    "    if n_prevs==0:\n",
    "        return test_metadata_df\n",
    "    \n",
    "    baboon_columns = [col for col in test_metadata_df.columns if col.startswith('baboon_id')]\n",
    "    max_samples = int(test_metadata_df[baboon_columns].sum(axis=0).max()) # max number of samples per baboon\n",
    "    dfs_list = []\n",
    "    \n",
    "    # create chunks of sub dataframes, where each df contains at most one row from each baboon.\n",
    "    # data is sorted by date from preprocess func.\n",
    "    # will be predicted in that order to ensure PREV already exists.\n",
    "    for i in range(max_samples):\n",
    "        ith_samples = pd.DataFrame()\n",
    "        for baboon_col in baboon_columns:\n",
    "            baboon_samples = test_metadata_df[test_metadata_df[baboon_col] == 1]\n",
    "            if i < len(baboon_samples):  # Check if the ith sample exists for this baboon\n",
    "                ith_samples = pd.concat([ith_samples, baboon_samples.iloc[[i]]])  # Append ith sample\n",
    "        dfs_list.append(ith_samples)\n",
    "\n",
    "    # use KDE to init test microbiome values from train distribution\n",
    "    col_dists = {}\n",
    "    microbiome_cols=train_data_df.columns\n",
    "    for col in microbiome_cols:\n",
    "        kde = gaussian_kde(train_data_df[col])  \n",
    "        col_dists[col] = kde\n",
    "    \n",
    "    # fill missing columns with values from distribition\n",
    "    for i in range(len(dfs_list)):\n",
    "        chunk=dfs_list[i]\n",
    "        for j in range(1, n_prevs + 1):\n",
    "            for col in microbiome_cols:\n",
    "                prev_col = f\"prev{j}_{col}\"\n",
    "                if prev_col not in chunk.columns:\n",
    "                    chunk[prev_col] = col_dists[col].resample(len(chunk))[0]  \n",
    "\n",
    "    return dfs_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Predict test: create a iterative prediction for test metadata (x_test), PREV are added in each iteration.\n",
    "    * microbiome_lst: microbes that will be used as PREV features\n",
    "    * microb: if given the function will only predict for it\n",
    "    * selected_features: ones selected in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(microbiome_lst, model, test_metadata_df_arg, n_prevs, selected_features,dfs_lst_arg, microb=\"\"):\n",
    "    \n",
    "    # assures no override\n",
    "    test_metadata_df=test_metadata_df_arg.copy()\n",
    "\n",
    "    # Use all microbe columns if microb == \"\", otherwise use the specified microbe column\n",
    "    if microb == \"\":\n",
    "        predict_columns = microbiome_lst\n",
    "    else:\n",
    "        if isinstance(microb, list): # recieved more then one -> list\n",
    "            predict_columns=microb\n",
    "        else:\n",
    "            predict_columns = [microb] # recieved one -> string\n",
    "\n",
    "    # no PREV needed: predict normally, no need in iterative prediction\n",
    "    if n_prevs == 0:\n",
    "        res_df = pd.DataFrame(model.predict(test_metadata_df[selected_features].to_numpy()), columns=predict_columns, index=test_metadata_df.index)\n",
    "        return res_df\n",
    "    \n",
    "    # when runnign all hyperparameters in a loop, need a copy for each code execution so there are no overrides\n",
    "    dfs_list=[df.copy() for df in dfs_lst_arg]\n",
    "\n",
    "    all_preds_list = []\n",
    "  \n",
    "    print('start predict')\n",
    "    for i in range(len(dfs_list)):\n",
    "        chunk=dfs_list[i]\n",
    "        \n",
    "        # create a prediction and concat as df to create df with all predictions\n",
    "        y_pred = model.predict(chunk[selected_features].to_numpy())\n",
    "        y_pred_df = pd.DataFrame(y_pred, columns=predict_columns, index=chunk.index)\n",
    "        all_preds_list.append(y_pred_df)\n",
    "\n",
    "        # write current predicted values as PREV features in the next chuncks\n",
    "        for j in range(1, n_prevs+1):\n",
    "            if i+j < len(dfs_list):\n",
    "                next_chunk=dfs_list[i+j] \n",
    "                next_chunk = next_chunk.merge(y_pred_df,how='left',on='sample',suffixes=[\"\",f\"_{j}_prev\"])\n",
    "                rename_cols = {f\"{microbe}_{j}_prev\": f\"prev{j}_{microbe}\" for microbe in microbiome_lst}\n",
    "                next_chunk.rename(columns=rename_cols, inplace=True)\n",
    "\n",
    "\n",
    "    y_pred_df_all = pd.concat(all_preds_list)\n",
    "    print('created predictions')\n",
    "\n",
    "    return y_pred_df_all\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iegq-2jE4Wx5"
   },
   "source": [
    "### Evaluate model\n",
    "* Normalize results\n",
    "* Use Bray Curtis to evaluate the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(y_pred, y_test, method_dic, is_microbe_wise):\n",
    "    \n",
    "    # Calculate the Bray-Curtis dissimilarity for each label column\n",
    "    bray_curtis_dissimilarity = [i for i in range(len(y_pred))]\n",
    "    for i in range(len(y_pred)):\n",
    "        bray_curtis_dissimilarity[i] = braycurtis(y_test[i, :], y_pred[i, :])\n",
    "\n",
    "    print('average bray curits dis is:', np.average(bray_curtis_dissimilarity))\n",
    "\n",
    "    # save result to local dataframe\n",
    "    if is_microbe_wise:\n",
    "        path_to_csv=os.path.join(base_path,'microbe_wise_output.csv')\n",
    "    else:\n",
    "        path_to_csv=os.path.join(base_path,'whole_data_analysis_output.csv')\n",
    "\n",
    "    if not os.path.exists(path_to_csv):\n",
    "        df = pd.DataFrame(columns=['selection', 'rf_0_prevs', 'lgbm_0_prevs', 'rf_3_prevs', 'lgbm_3_prevs', 'rf_6_prevs', 'lgbm_6_prevs', 'rf_10_prevs', 'lgbm_10_prevs'])\n",
    "        df.to_csv(path_to_csv, index=False)\n",
    "\n",
    "    df=pd.read_csv(path_to_csv,header=0)\n",
    "    df.set_index('selection', inplace=True)\n",
    "    \n",
    "    f_o_w=f\"{method_dic['filter']}{method_dic['wrapper']}\"\n",
    "    if f_o_w==\"\": ind='No Selection'\n",
    "    else: ind=f\"{method_dic['filter']}{method_dic['wrapper']}_{method_dic['n_features']}\"\n",
    "\n",
    "    col=f\"{method_dic['model']}_{method_dic['n_prevs']}_prevs\"\n",
    "    df.at[ind, col] = f\"{np.average(bray_curtis_dissimilarity):.4f}\"\n",
    "    print(ind,col)\n",
    "\n",
    "    display(df)\n",
    "    df.to_csv(path_to_csv,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_result(y_matrix):\n",
    "   y_normed = []\n",
    "   for row in y_matrix:\n",
    "     row_normed = row/sum(row)\n",
    "     y_normed.append(row_normed)\n",
    "   return np.array(y_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, y_predict, method, is_microbe_wise=False):\n",
    "  # reorder them so we can compare microbiome with numpy, and not pandas\n",
    "  y_predict = y_predict.reindex(y_test.index)\n",
    "\n",
    "  # normalize the results- microbiome sum to 1\n",
    "  y_predict_normalized = normalize_result(y_predict.values)\n",
    "\n",
    "  # braycurtis etc.\n",
    "  calc_score(y_predict_normalized, y_test.values, method, is_microbe_wise)\n",
    "  print('\\ncalculated score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFiBx8P6wTb3"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCnh-bAh8wyN"
   },
   "source": [
    "#### Correlation-based Selection: \n",
    "* Select features based on their correlation with the target variable (e.g., Pearson or Spearman correlation).\n",
    "* can be chosen my average / medain of all values across the microbiome- we chose average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "505ffGXssrY_"
   },
   "outputs": [],
   "source": [
    "def correlation_feature_selection(processed_metadata_df, data_df, method, n_features):\n",
    "  print(f'#### Method: {method} ####\\n')\n",
    "  microbiome_columns = data_df.columns\n",
    "\n",
    "  # Iterate over each metadata feature and calculate correlation with each microbiome\n",
    "  correlations = {}\n",
    "  for meta_col in processed_metadata_df.columns:\n",
    "      meta_correlations = []\n",
    "      for cur_micro in microbiome_columns:\n",
    "          corr_value = data_df[cur_micro].corr(processed_metadata_df[meta_col], method=method) #spearman / pearson\n",
    "          meta_correlations.append(corr_value)\n",
    "\n",
    "      correlations[meta_col] = meta_correlations\n",
    "\n",
    "  # Convert to DataFrame with absolute values to infer significance\n",
    "  correlation_df = pd.DataFrame.from_dict(correlations, orient='index',columns=microbiome_columns).abs()\n",
    "  correlation_df['average']=correlation_df.mean(axis=1)\n",
    "  correlation_df['median']=correlation_df.median(axis=1)\n",
    "\n",
    "  n_chosen=correlation_df['average'].nlargest(n=n_features).index.values\n",
    "\n",
    "  print('N chosen features:')\n",
    "  print(n_chosen)\n",
    "\n",
    "  return n_chosen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqZ1tnkWQUnd"
   },
   "source": [
    "#### Variance Threshold: \n",
    "* Remove features with low variance (those that donâ€™t change much across the dataset).\n",
    "* we tested this feature with 3 different variance thresholds: 0.1 / 0.3 / 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "pq1QekxnBDqQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "In-uFr2AQdVY"
   },
   "outputs": [],
   "source": [
    "def variance_feature_selection(processed_metadata_df, threshold=0.6):\n",
    "  print(f'#### Threshold: {threshold} ####\\n')\n",
    "\n",
    "  processed_metadata_df_columns=processed_metadata_df.columns\n",
    "\n",
    "  # create selector\n",
    "  selector = VarianceThreshold(threshold=threshold)\n",
    "  transformed_data = selector.fit_transform(processed_metadata_df[processed_metadata_df_columns])\n",
    "\n",
    "  # Convert to DataFrame features > TH\n",
    "  selected_features_df = pd.DataFrame(transformed_data, columns=[col for col in processed_metadata_df_columns if selector.variances_[processed_metadata_df_columns.index(col)] > threshold])\n",
    "\n",
    "  print(\"Selected features based on variance threshold:\\n\")\n",
    "  print(selected_features_df.columns)\n",
    "\n",
    "  print(f\"selected features count: {len(selected_features_df.columns)}\")\n",
    "\n",
    "  return list(selected_features_df.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PF_8owGHXC0G"
   },
   "source": [
    "#### MinimumRedundancyMaximumRelevance: \n",
    "* a feature selection technique used to select a subset of features that are both highly relevant to the target variable and minimally redundant with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJd_9fdfMHCg"
   },
   "source": [
    "* mrmr_classif, for feature selection when the target variable is categorical (binary or multiclass).\n",
    "* mrmr_regression, for feature selection when the target variable is numeric.\n",
    "* Note: the output of mrmr_classif is a list containing K selected features. This is a ranking, therefore, if you want to make a further selection, take the first elements of this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2b1Fwy9kS-e",
    "outputId": "b804f3c4-4483-47a4-cd7b-ab6013a4313b"
   },
   "outputs": [],
   "source": [
    "# source: https://github.com/smazzanti/mrmr\n",
    "# !pip install mrmr_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "S1vOSu8TkWrS"
   },
   "outputs": [],
   "source": [
    "import mrmr\n",
    "from mrmr import mrmr_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKtji34PkZa9"
   },
   "outputs": [],
   "source": [
    "def fs_mrmr(processed_metadata_df,processed_data_df,n_features):\n",
    "\n",
    "  d={k: 0 for k in processed_metadata_df.columns}\n",
    "\n",
    "  # run uppon each microbe, the dict represents the number of times each feature was found most significant.\n",
    "  # low value indicates low significance\n",
    "  for micro in processed_data_df.columns:\n",
    "    # return a list when lower index is more significant\n",
    "    selected_features = mrmr_classif(X=processed_metadata_df, y=processed_data_df[micro], K=len(processed_metadata_df.columns))\n",
    "    sig=0\n",
    "    for f in selected_features:\n",
    "      d[f]+=sig\n",
    "      sig+=1\n",
    "    print(\"mrmr for:\", micro, selected_features)\n",
    "  print(d)\n",
    "\n",
    "  #take the n features with lowest values\n",
    "  top_features = [key for key, value in sorted(d.items(), key=lambda item: item[1], reverse=False)[:n_features]] \n",
    "\n",
    "  return top_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLGuK3DEq-QH"
   },
   "source": [
    "#### Recursive Feature Elimination (RFE): \n",
    "* Iteratively builds a model and removes the least important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "f0ZC1atgid0K"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "gUGZc-84rJrr"
   },
   "outputs": [],
   "source": [
    "# Not parallel\n",
    "def fs_RFE(X_train, y_train,n_features,model):\n",
    "\n",
    "  # Initialize array to keep track of how many times each feature is selected\n",
    "  best_features =np.array([0 for i in range(X_train.shape[1])])\n",
    "\n",
    "  #for microbe in label_cols:\n",
    "  for col in y_train.T:\n",
    "    y_micro = col\n",
    "    rfe = RFE(model, n_features_to_select=n_features)\n",
    "    rfe.fit(X_train, y_micro) # y must be 1-D vector\n",
    "    # best features: rfe.support_\n",
    "    # returns a Boolean mask (array) of shape (n_features,), where True/False indicates if the feature was selected.\n",
    "\n",
    "    # best features for this specific micro\n",
    "    best_features = best_features + np.array(rfe.support_).astype(int)\n",
    "\n",
    "  # find the top features in average - array of indexes - DEBATEABLE\n",
    "  top_n_features = np.argsort(best_features)[-n_features:][::-1]\n",
    "\n",
    "\n",
    "  return top_n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with parallel n_jobs\n",
    "def fs_RFE(X_train, y_train, n_features, model):\n",
    "\n",
    "    n_jobs = 5\n",
    "\n",
    "    # Initialize array to keep track of how many times each feature is selected\n",
    "    best_features = np.zeros(X_train.shape[1], dtype=int)\n",
    "    print(\"initialized best_features array, start proccessing columns\")\n",
    "\n",
    "    # runs in parallel for each output label\n",
    "    def process_single_column(y_col):\n",
    "        rfe = RFE(model, n_features_to_select=n_features)\n",
    "        rfe.fit(X_train, y_col)  # Fit RFE for the given column\n",
    "        print(\"at RFE, done with one\")\n",
    "        return np.array(rfe.support_).astype(int)\n",
    "\n",
    "    # Parallel execution for each column in y_train.T\n",
    "    results = Parallel(n_jobs=n_jobs, backend=\"threading\")(delayed(process_single_column)(col) for col in y_train.T)\n",
    "\n",
    "    for result in results:\n",
    "        best_features += result\n",
    "\n",
    "    # Find the top n features by average selection\n",
    "    top_n_features = np.argsort(best_features)[-n_features:][::-1]\n",
    "\n",
    "    return top_n_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdA_NWl8ry6r"
   },
   "source": [
    "#### Forward Selection: \n",
    "* Starts with no features and adds one feature at a time based on model performance.\n",
    "#### Backward Elimination: \n",
    "* Starts with all features and removes the least significant ones one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "ciiA5F45ryT6"
   },
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "xJqfK4m2sSlR"
   },
   "outputs": [],
   "source": [
    "is_forawrd = True # False for backwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "zXKh7ed8r63_"
   },
   "outputs": [],
   "source": [
    "def fs_SFS(X_train,y_train,n_features, is_forawrd, model):\n",
    "\n",
    "  sfs = SFS(model, k_features=n_features, forward=is_forawrd, floating=False)\n",
    "  sfs.fit(X_train, y_train) # y is matrix\n",
    "  selected_features_indices = list(sfs.k_feature_idx_)\n",
    "\n",
    "  return selected_features_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04klVd_3vBLz"
   },
   "source": [
    "#### Boruta algorithm: \n",
    "* built around the Random Forest classifier and aims to find features that are strongly or weakly relevant to the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8M-KrCxpvP8L",
    "outputId": "47397fc3-71a1-48b4-dcb5-9fde711689a1"
   },
   "outputs": [],
   "source": [
    "# !pip install Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "XDhhN7LMskT_"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "\n",
    "import concurrent.futures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "qeL7kLHUvI-I"
   },
   "outputs": [],
   "source": [
    "# Not parallel\n",
    "### expects discrete values\n",
    "def fs_boruta(X_train,y_train,n_features, model):\n",
    "\n",
    "  best_features =np.array([0 for i in range(X_train.shape[1])])\n",
    "\n",
    "  for col in y_train.T:\n",
    "    y_micro = col\n",
    "    boruta_selector = BorutaPy(model, n_estimators='auto', random_state=42)\n",
    "    boruta_selector.fit(X_train, y_micro)\n",
    "\n",
    "    # boruta_selector.support_ returns a Boolean mask (array) of shape (n_features,), where True/False indicates if the feature was selected.\n",
    "    # best features for this specific microbe\n",
    "    best_features = best_features + np.array(boruta_selector.support_).astype(int)\n",
    "\n",
    "  # find the top features in average - array of indexes\n",
    "  top_n_features = np.argsort(best_features)[-n_features:][::-1]\n",
    "\n",
    "\n",
    "  return top_n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel processing\n",
    "\n",
    "def process_boruta_for_column(X_train, y_micro, model):\n",
    "    boruta_selector = BorutaPy(model, n_estimators='auto', random_state=42)\n",
    "    boruta_selector.fit(X_train, y_micro)\n",
    "    return np.array(boruta_selector.support_).astype(int)\n",
    "\n",
    "def fs_boruta(X_train, y_train, n_features, model, label_cols):\n",
    "    best_features = np.zeros(X_train.shape[1], dtype=int)\n",
    "\n",
    "    # Use ProcessPoolExecutor for parallel processing\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=20) as executor:\n",
    "        # Submit jobs for each column in y_train\n",
    "        futures = [executor.submit(process_boruta_for_column, X_train, col, model) for col in y_train.T]\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            best_features += future.result()\n",
    "\n",
    "    # Find the top features in average - array of indexes\n",
    "    top_n_features = np.argsort(best_features)[-n_features:][::-1]\n",
    "\n",
    "    return top_n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The FS Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ol5bbIvfvfqC"
   },
   "outputs": [],
   "source": [
    "def pipeline(processed_metadata_df, processed_data_df,filt,wrapper,n_features,is_forawrd,model_type, is_per_microbe):\n",
    "  \n",
    "  print(\"start pipeline\")\n",
    "\n",
    "  # init selected features to be all\n",
    "  selected_features=np.array(processed_metadata_df.columns)\n",
    "\n",
    "  # filter features before run model\n",
    "  if filt:\n",
    "    print(f'start filtering using: {filt}')\n",
    "    if filt == 'corr':\n",
    "      selected_features= correlation_feature_selection(processed_metadata_df, processed_data_df, 'pearson',n_features) #spearman\n",
    "    if filt == 'var':\n",
    "      selected_features=variance_feature_selection(processed_metadata_df)\n",
    "    if filt == 'mrmr':\n",
    "      selected_features=fs_mrmr(processed_metadata_df,processed_data_df,n_features)\n",
    "\n",
    "    print('done filtering')\n",
    "    processed_metadata_df = processed_metadata_df[list(selected_features)]\n",
    "\n",
    "\n",
    "  print('start create model')\n",
    "  x_train=processed_metadata_df.to_numpy()\n",
    "  y_train=processed_data_df.to_numpy()\n",
    "\n",
    "  if model_type == 'rf':\n",
    "    model = RandomForestRegressor(n_jobs=3)\n",
    "  if model_type == 'lgbm':\n",
    "    base_model = lgb.LGBMRegressor(verbosity=-1)\n",
    "    # Wrap the LightGBM regressor in MultiOutputRegressor to handle multi-output labels\n",
    "    model = base_model\n",
    "    if not is_per_microbe:\n",
    "      model = MultiOutputRegressor(base_model)\n",
    "\n",
    "  print('created model')\n",
    "\n",
    "  if wrapper:\n",
    "    print(f'start filtering using: {wrapper}')\n",
    "    # fit wrapper model inside the function\n",
    "    if wrapper == 'RFE':\n",
    "      top_n_features=fs_RFE(x_train,y_train,n_features,model)\n",
    "    if wrapper == 'SFS':\n",
    "      top_n_features=fs_SFS(x_train,y_train,n_features, is_forawrd, model)\n",
    "    if wrapper == 'Boruta':\n",
    "      top_n_features=fs_boruta(x_train,y_train,n_features, model)\n",
    "    \n",
    "    features = processed_metadata_df.columns\n",
    "    selected_features = features[top_n_features] \n",
    "\n",
    "    print(f'selected_features: {selected_features}')\n",
    "\n",
    "\n",
    "    # exclude unselected features from x_train\n",
    "    tmp_x=x_train[:, top_n_features]\n",
    "    x_train=tmp_x\n",
    "\n",
    "  print('start fit model')\n",
    "  model.fit(x_train, y_train)\n",
    "  print('done fit model')\n",
    "\n",
    "  return model, selected_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccN-SXHyATBL"
   },
   "source": [
    "## RUN MODEL\n",
    "* Option 1: Whole data version- predicting for the whole microbiome together\n",
    "* Option 2: Predict for each microbe seperatly - create prediction for each microbe and then evaluate them all together\n",
    "    * Unused due to long infeasible execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt= None # None /'corr' / 'var' / 'mrmr'\n",
    "wrapper= 'RFE' # None / RFE / SFS / Boruta\n",
    "model_type = 'rf' # rf / knn / lgbm\n",
    "n_features=80 #hyper parameter\n",
    "is_forawrd=True\n",
    "n_prevs=0\n",
    "per_monkey = True\n",
    "\n",
    "method={'filter':filt, 'wrapper':wrapper,'model':model_type,'n_features':n_features,'is_forawrd':is_forawrd,'n_prevs':n_prevs,'per_monkey':per_monkey}\n",
    "method = {k: (v if v is not None else \"\") for k, v in method.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole data version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UslWDTsTqYZm"
   },
   "outputs": [],
   "source": [
    "def predict_for_all_microbe_together(metadata_df, data_df, test_data_df_arg=[]):\n",
    "\n",
    "    processed_metadata_df, processed_data_df= preprocess(metadata_df, data_df)\n",
    "\n",
    "    if len(test_data_df_arg)!=0:\n",
    "        # if we want to predict for the actual test data- we need to split it accordingly\n",
    "        x_train=processed_metadata_df\n",
    "        y_train=processed_data_df\n",
    "        x_test, y_test=preprocess(test_data_df_arg[0],None,False)\n",
    "        print(f'number of samples in train dataset: {len(x_train)}')\n",
    "        \n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test = split_per_monkey(processed_metadata_df, processed_data_df)\n",
    "    \n",
    "    x_train = add_prev(x_train, y_train,n_prevs)\n",
    "\n",
    "    # send only columns that do not contain our baboons- different in tarin and test\n",
    "    model, selected_features=pipeline(x_train, y_train, filt, wrapper,n_features,is_forawrd,model_type, False)\n",
    "\n",
    "    # some features only exist in train and not test -> need to find them and manualy add those columns to test\n",
    "    test_baboons=[col for col in x_test.columns if 'baboon_id' in col]\n",
    "    selected_features_unsafe=[col for col in selected_features.tolist() if ('baboon_id' in col and col not in test_baboons)]\n",
    "\n",
    "    # fill 0 all required babbon_id in test features\n",
    "    for i in range(len(selected_features)):\n",
    "        if selected_features[i] in selected_features_unsafe:\n",
    "            print(f'{selected_features[i]} not in test - fill 0')\n",
    "            x_test[selected_features[i]]=0\n",
    "\n",
    "    chunks=process_test_metadata(x_test, y_train, n_prevs)\n",
    "            \n",
    "    y_predict=predict_test(y_train.columns, model, x_test, n_prevs, selected_features, chunks)\n",
    "\n",
    "    \n",
    "    if len(test_data_df_arg)!=0:\n",
    "        y_predict.to_csv(f'{base_path}whole_data_final_prediction.tsv', index=True,sep='\\t')\n",
    "        return\n",
    "    \n",
    "    evaluate(y_test, y_predict, method, is_microbe_wise=False)\n",
    "\n",
    "\n",
    "# Only train\n",
    "predict_for_all_microbe_together(metadata_df, data_df)\n",
    "\n",
    "# Test for real predictions\n",
    "predict_for_all_microbe_together(updated_train_metadata_df, updated_train_data_df, [actual_test_metadata_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for each microbe seperatly - \\*unused\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correlation between microbes\n",
    "# choose pearson / spearman\n",
    "def get_correlation_mat(data_df, method):\n",
    "  print(f'#### Method: {method} ####\\n')\n",
    "\n",
    "  microbiome_columns = data_df.columns\n",
    "\n",
    "  # Iterate over each microbe and calculate correlation with all microbiome\n",
    "  correlations = pd.DataFrame(0, index=microbiome_columns, columns=microbiome_columns)\n",
    "\n",
    "  for col in range(len(microbiome_columns)):\n",
    "    for index in range(col,len(microbiome_columns)):\n",
    "      corr=data_df[microbiome_columns[index]].corr(data_df[microbiome_columns[col]], method=method) #spearman pearson\n",
    "      # Convert to absolute values to infer correlations between microbiome\n",
    "      correlations.loc[microbiome_columns[index], microbiome_columns[col]] = abs(corr)\n",
    "  \n",
    "  correlations = correlations.where(np.tril(np.ones(correlations.shape)).astype(bool), correlations.T)\n",
    "  \n",
    "  print('correlations: \\n')\n",
    "  display(correlations)\n",
    "\n",
    "  return correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "O7W83h8KTf_0",
    "outputId": "4ca2e380-0d4b-4af8-cd3d-24de61a2abe4"
   },
   "outputs": [],
   "source": [
    "def predict_for_each_microbe_sep(metadata_df, data_df, test_data_df_arg=[]):\n",
    "\n",
    "  processed_metadata_df, processed_data_df= preprocess(metadata_df, data_df)\n",
    "\n",
    "  if len(test_data_df_arg)!=0:\n",
    "        # if we want to predict for the actual test data- we need to split it accordingly\n",
    "        x_train=processed_metadata_df\n",
    "        y_train=processed_data_df\n",
    "        x_test, y_test=preprocess(test_data_df_arg[0],None,False)\n",
    "        print(x_test)\n",
    "        print(f'number of samples in train dataset: {len(x_train)}')\n",
    "  else:\n",
    "    x_train, x_test, y_train, y_test = split_per_monkey(processed_metadata_df, processed_data_df)\n",
    "\n",
    "  # add all prevs in one function call and then filter columns each time\n",
    "  x_columns=x_train.columns\n",
    "  x_train_prev = add_prev(x_train, y_train,n_prevs)\n",
    "\n",
    "  # get correlations between microbiome\n",
    "  corr_mat=get_correlation_mat(y_train, 'spearman')\n",
    "\n",
    "  all_pred_df=pd.DataFrame()\n",
    "  \n",
    "  chunks=process_test_metadata(x_test, y_train, n_prevs)\n",
    "\n",
    "\n",
    "  count = 0\n",
    "  for microb in y_train.columns:\n",
    "    print(\"calcing for\", microb)\n",
    "\n",
    "    # find the most correlated microbiome to add as features\n",
    "    corr_microbiome=corr_mat[corr_mat[microb] >= 0.6].index.tolist() # can be hyper parameter , lower th will lead to a lot of correlated microbs\n",
    "    print(f'found high correlations between: {corr_microbiome}')\n",
    "\n",
    "    cur_x_columns=x_columns.to_list()+[f'prev{prev}_{microbe}' for microbe in corr_microbiome for prev in range(1, n_prevs+1)]\n",
    "    x_train_microbe=x_train_prev[cur_x_columns]\n",
    "\n",
    "    count +=1\n",
    "    print(f'count: {count}')\n",
    "\n",
    "    cur_y_train=y_train[[microb]]\n",
    "    model, selected_features=pipeline(x_train_microbe,cur_y_train,filt,wrapper,n_features,is_forawrd,model_type, True)\n",
    "\n",
    "    # some features only exist in train and not test -> need to find them and manualy add those columns to test\n",
    "    test_baboons=[col for col in x_test.columns if 'baboon_id' in col]\n",
    "    selected_features_unsafe=[col for col in selected_features.tolist() if ('baboon_id' in col and col not in test_baboons)]\n",
    "\n",
    "    # fill 0 all required babbon_id in test features\n",
    "    for i in range(len(selected_features)):\n",
    "        if selected_features[i] in selected_features_unsafe:\n",
    "            print(f'{selected_features[i]} not in test - fill 0')\n",
    "            x_test[selected_features[i]]=0\n",
    "\n",
    "    y_predict=predict_test(corr_microbiome, model,x_test, n_prevs, selected_features,chunks, microb)\n",
    "\n",
    "    all_pred_df[microb]=y_predict # add microb prediction to df as new column\n",
    "\n",
    "\n",
    "  if len(test_data_df_arg)!=0:\n",
    "        all_pred_df.to_csv(f'{base_path}each_microbe_prediction.tsv', index=True,sep='\\t')\n",
    "        return\n",
    "  \n",
    "  evaluate(y_test, all_pred_df, method, is_microbe_wise=True)\n",
    "\n",
    "\n",
    "\n",
    "# Only train\n",
    "predict_for_each_microbe_sep(metadata_df, data_df)\n",
    "\n",
    "# Test for real predictions\n",
    "predict_for_each_microbe_sep(updated_train_metadata_df, updated_train_data_df, [actual_test_metadata_df])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(is_microbe_wise,n_prev, show_none_only, n_features):\n",
    "    if is_microbe_wise:\n",
    "        path=os.path.join(base_path,'microbe_wise_output.csv')\n",
    "        title='Microbe Wise'\n",
    "    else:\n",
    "        path=os.path.join(base_path,'whole_data_analysis_output.csv')\n",
    "        title='Whole Data Analysis'\n",
    "        \n",
    "    df=pd.read_csv(path,header=0)\n",
    "    df.set_index('selection', inplace=True)\n",
    "\n",
    "    if n_prev:\n",
    "        df=df[[col for col in df.columns if str(n_prev) in col]]\n",
    "    if show_none_only:\n",
    "        df=df.iloc[0:1,:]\n",
    "    if n_features:\n",
    "        df=df.T[[col for col in df.T.columns if str(n_features) in col]].T\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(df, annot=True, cmap='coolwarm', cbar_kws={'label': 'Value'}, fmt='.2f')\n",
    "\n",
    "    plt.title(f'Heatmap - {title}')\n",
    "    plt.xlabel('Model Type')\n",
    "    plt.ylabel('Filter / Wrapper _ Number of Features')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "heatmap(False,False, False, False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
